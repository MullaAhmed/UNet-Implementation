{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from keras.utils import normalize\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "from patchify import patchify, unpatchify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_image_stack=tiff.imread()\n",
    "large_mask_stack=tiff.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_patches=[]\n",
    "for img in range(large_image_stack.shape[0]):\n",
    "    large_image=large_image_stack[img]\n",
    "    patches_mask=patchify(large_image,(256,256),step=256)\n",
    "\n",
    "    for i in range(patches_mask.shape[0]):\n",
    "        for j in range(patches_mask.shape[1]):\n",
    "\n",
    "            single_patch_img= patches_mask[i,j,:,:]\n",
    "            single_patch_img=single_patch_img.astype('float32')/255\n",
    "\n",
    "            all_img_patches.append(single_patch_img)\n",
    "\n",
    "images=np.array(all_img_patches)\n",
    "images=np.expand_dims(images,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask_patches=[]\n",
    "for mask in range(large_mask_stack.shape[0]):\n",
    "    large_mask=large_mask_stack[mask]\n",
    "    patches_mask=patchify(large_mask,(256,256),step=256)\n",
    "\n",
    "    for i in range(patches_mask.shape[0]):\n",
    "        for j in range(patches_mask.shape[1]):\n",
    "\n",
    "            single_patch_mask= patches_mask[i,j,:,:]\n",
    "            single_patch_mask=single_patch_mask.astype('float32')/255\n",
    "\n",
    "            all_mask_patches.append(single_patch_mask)\n",
    "\n",
    "masks=np.array(all_mask_patches)\n",
    "masks=np.expand_dims(mask s,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(images,masks,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT=images.shape[1]\n",
    "IMG_WIDTH=images.shape[2]\n",
    "IMG_CHANNELS=images.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
    "model=build_unet(input_shape)\n",
    "model.compile(optimizer=Adam(lr=1e-3),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=24 \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_gen_args=dict(rotation_range=90,\n",
    "                       width_shift_range=0.3,\n",
    "                       shear_range=0.5,\n",
    "                       zoom_range=0.3\n",
    "                       horizantal_flip=True,\n",
    "                       vertical_flip=True,\n",
    "                       fill_mode=\"reflect\")\n",
    "\n",
    "maskdata_gen_args=dict(rotation_range=90,\n",
    "                       width_shift_range=0.3,\n",
    "                       shear_range=0.5,\n",
    "                       zoom_range=0.3\n",
    "                       horizantal_flip=True,\n",
    "                       vertical_flip=True,\n",
    "                       fill_mode=\"reflect\",\n",
    "                       preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "image_data_generator.fit(x_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_data_generator.flow(x_train, seed=seed)\n",
    "valid_img_generator = image_data_generator.flow(x_test, seed=seed)\n",
    "\n",
    "mask_data_generator = ImageDataGenerator()\n",
    "mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
    "mask_generator = mask_data_generator.flow(y_train, seed=seed)\n",
    "valid_mask_generator = mask_data_generator.flow(y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask)\n",
    "\n",
    "my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
    "\n",
    "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image_generator.next()\n",
    "y = mask_generator.next()\n",
    "for i in range(0,1):\n",
    "    image = x[i]\n",
    "    mask = y[i]\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[:,:,0], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask[:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "steps_per_epoch = 3*(len(x_train))//batch_size\n",
    "history = model.fit(my_generator, validation_data=validation_datagen, steps_per_epoch=steps_per_epoch, validation_steps=steps_per_epoch, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IOU\n",
    "import random \n",
    "y_pred=model.predict(x_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "union = np.logical_or(y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)\n",
    "\n",
    "#Predict on a few images\n",
    "#model = get_model()\n",
    "#model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
    "\n",
    "test_img_number = random.randint(0, len(x_test))\n",
    "test_img = x_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
